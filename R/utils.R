#'
#' Fit occupancy models in parallel
#'
#' @description Wrapper around ppl_run_pipe_dst1 (fit step) for furrr parallel calls
#' @param .sp_code Species SAFRING code
#' @param .year Year to run to the pipeline for
#' @param .spatial Whether a spatial model should be fit. Defaults to FALSE.
#' @param .config Config object from \code{\link{configPipeline}}
#' @param .steps Character vector with the steps the pipeline should run. Typically
#' c("fit", "diagnose"). However, be aware that "diagnose" uses a lot of RAM.
#' @param time_limit Computation time limit for each core in seconds.
#'
#' @export
#' @example
#' \dontrun{}
pipe_prll_fit <- function(.sp_code, .year, .spatial = FALSE, .config,
                          .steps = c("fit", "diagnose"), time_limit = NULL){


    if(!is.null(time_limit)){
        setTimeLimit(cpu = Inf, elapsed = time_limit, transient = TRUE)
        on.exit({
            setTimeLimit(cpu = Inf, elapsed = Inf, transient = FALSE)
        })
    }


    # Pipeline module 1
    tryCatch({

        out_dst1 <- ppl_run_pipe_dst1(sp_code = .sp_code,
                                      year = .year,
                                      config = .config,
                                      steps = .steps,
                                      force_gee_dwld = FALSE,
                                      monitor_gee = TRUE,
                                      force_site_visit = TRUE,
                                      force_abap_dwld = FALSE,
                                      spatial = .spatial,
                                      print_fitting = TRUE)

        message(paste("Pipeline DST1 status =", out_dst1))

    }, error = function(ex) {

        msg <- ex$message

        # Was it a timeout?
        pattern <- gettext("reached elapsed time limit", "reached CPU time limit", domain="R")
        pattern <- paste(pattern, collapse = "|")

        # If it was a timeout then, report and log it
        if (regexpr(pattern, msg) != -1L) {

            ex <- paste("Computation_time_exceeded_sp", .sp_code, .year, sep = "_")
            message(paste(ex, ":", round(time_limit/60), "minutes"))
            conv_file <- file.path(.config$out_dir, "reports", paste0(ex, ".txt"))
            sink(conv_file)
            print(paste(ex, ":", round(time_limit/60), "minutes"))
            sink()

            # Find most recent log file
            logfile <- file.info(list.files(file.path(.config$out_dir, "reports"), full.names = TRUE)) %>%
                dplyr::mutate(file = row.names(.)) %>%
                dplyr::filter(grepl(paste0("pipe_log_", .config$module), file)) %>%
                dplyr::arrange(desc(ctime)) %>%
                dplyr::slice(1) %>%
                dplyr::pull(file)

            # Open log with current time
            s <- Sys.time()
            attr(s,"tzone") <- "Africa/Johannesburg"

            ppl_log <- c(date_time = format(s), species = .sp_code, model = "occ",
                         year = .year, data = NA, fit = NA, diagnose = NA, summary = NA,
                         package = .config$package, notes = NA)

            # Log fit status
            fit_status <- 4
            ppl_log["fit"] <- fit_status

            # Save fit if the process was successful or return the status otherwise
            createLog(.config, logfile, full_log = ppl_log)

            out_dst1 <- 4

            message(paste("Pipeline DST1 status =", out_dst1))

        } else { # If it was not a timeout, report the message
            message(msg)
            out_dst1 <- 3
        }

        message(paste("Pipeline DST1 status =", out_dst1))

    })

}


#'
#' Generate fit status messages
#'
#' @param .fit_out Fit status object generated by \code{\link{ppl_fit_occu_model}}
#' @param .year Year to run to the pipeline for
#' @param .sp_code Species SAFRING code
#' @param .config Config object from \code{\link{configPipeline}}
#'
#' @export
#' @example
#' \dontrun{}
logFitStatus <- function(.fit_out, .year, .sp_code, .config){

    if(is.numeric(.fit_out)){ # this immediately flags a problem

        min_pentads <- 2*length(.config$occ_mod)

        txt <- dplyr::case_when(.fit_out == 1 ~ paste0("no_detections_", .year,"_", .sp_code, ".txt"),
                                .fit_out == 2 ~ paste0("less_than_", min_pentads, "_pentads_", .year,"_", .sp_code, ".txt"),
                                .fit_out == 3 ~ paste0("model_fit_failed_", .year,"_", .sp_code, ".txt"))

        conv_file <- file.path(.config$out_dir, .sp_code, txt)
        sink(conv_file)
        print(gsub(".txt", "", txt))
        sink()
        message(gsub(".txt", "", txt)) # to console

        out <- .fit_out

    } else {
        out <- 0
    }

    return(out)

}

#' Create pipeline event log
#'
#' @description This function will create a customized log entry for a log file
#' that records the activity of the pipeline. More precisely, it will record the
#' time, species and outcome of data preparation, model fitting, diagnostics and
#' preparation.
#' @param config A list with pipeline configuration parameters.
#' See \code{\link{configPipeline}} and \code{\link{configPipeline}}.
#' @param log_file Optional. A character string with the path to the file that
#' should be updated. If NULL (default) a new log file will be created.
#' @param date_time Optional. A character string with the log date. If NULL (default)
#' the time given by \code{\link{Sys.time}}, formatted as SAST will be used.
#' @param species SAFRING code of the species the log corresponds to.
#' @param model Type of model being processed. Either "occ" or "ssm".
#' @param year Year the model is fit for.
#' @param data Data preparation status. Defaults to NA.
#' @param fit model fitting status. Defaults to NA.
#' @param diagnose Model diagnostics status. Defaults to NA.
#' @param summary Model summary status. Defaults to NA.
#' @param package A character string with the name of the package that should be
#' used to fit models. Currently, only `spOccupancy` for occupancy and `jagsUI`
#' for state-space modelling are supported.
#' maintained.
#' @param notes Any additional comments. Defaults to NA.
#' @param full_log Optionally, we can pass a full vector log, with all the above
#' elements. In this case, all other arguments but \code{config} and \code{logfile}
#' will be ignored.
#'
#' @return A .csv will be saved on the reports directory. The location of this
#' directory is configured in the configuration object passed as \code{config} at
#' \code{config$output_dir}.
#' @export
#' @example
#' \dontrun{}
createLog <- function(config, log_file = NULL, date_time = NULL, species = NULL,
                      model = NULL, year = NA, data = NA, fit = NA, diagnose = NA,
                      summary = NA, package = NA, notes = "", full_log = NULL){

    s <- Sys.time()
    attr(s,"tzone") <- "Africa/Johannesburg"
    today <- format(s, format = "%Y-%m-%d")
    now <- format(s, format = "%H%M%S")

    if(is.null(date_time)){
        date_time <- format(s)
    }

    if(is.null(full_log)){
        new_log <- c(date_time, species, model, year, data, fit, diagnose, summary, package, notes)
    } else {
        new_log <- full_log
    }


    if(is.null(log_file)){
        log_file <- file.path(config$out_dir, "reports", paste0("pipe_log_", config$module, "_", today,"_", now,".csv"))
        log <- data.frame(date_time = character(),
                          species = numeric(),
                          model = character(),
                          year = numeric(),
                          data = numeric(),
                          fit = numeric(),
                          diagnose = numeric(),
                          summary = numeric(),
                          package = character(),
                          notes = character())
        utils::write.csv(log, log_file, row.names = FALSE)
        message(paste("log file created:", log_file))
    }

    log <- utils::read.csv(log_file)
    new_row <- nrow(log) + 1

    log[new_row, ] <- new_log

    utils::write.csv(log, log_file, row.names = FALSE)

}


#' Create a combined file for export to data mart
#'
#' @param config A list with pipeline configuration parameters.
#' See \link{configPipeline}
#' @param type A character string with three options: "abu", for abundance estimates files,
#' or "dst" for occupancy estimates files.
#'
#' @return It will create a file in `config$out_dir/exports` combining all files of the selected
#' type of all species and years in `config$years`.
#' @export
#'
#' @examples
createCombinedExportFile <- function(config, type = c("abu", "dst")){

    type <- match.arg(type)

    if(type == "abu"){

        abu_out <- data.frame()

        for(i in 1:length(config$species)){

            sp_code <- config$species[i]

            abu_file <- setSpOutFilePath("ssm_pred", config, config$years_ch, sp_code, "_all.csv")

            if(file.exists(abu_file)){
                new_abu <- utils::read.csv(abu_file)
                new_abu <- round(new_abu, 3)
                abu_out <- dplyr::bind_rows(abu_out, new_abu)
            } else {
                abu_out <- abu_out
            }

        }

        utils::write.csv(abu_out,
                         file.path(config$out_dir, "export", paste0("ssm_pred_", config$years_ch, "_", config$region, "_all_all.csv")),
                         row.names = FALSE)
    }

    if(type == "dst"){

        dst_out <- data.frame()

        for(i in 1:length(config$species)){

            sp_code <- config$species[i]

            message(paste("Processing species", sp_code, i, "of", length(config$species)))

            for(y in 1:length(config$years)){

                yr <- config$years[y]
                dst_file <- setSpOutFilePath("occu_pred", config, yr, sp_code, ".csv")

                if(file.exists(dst_file)){

                    new_dst <- utils::read.csv(dst_file) %>%
                        dplyr::mutate(dplyr::across(dplyr::where(is.numeric), ~ round(.x, 3)))

                    dst_out <- dplyr::bind_rows(dst_out, new_dst)

                } else {
                    dst_out <- dst_out
                }

            }

        }

        utils::write.csv(dst_out, setSpOutFilePath("occu_pred", config, config$years_ch, "export", "_all.csv"),
                         row.names = FALSE)
    }
}


#' Set a standard path for a pipeline output file associated with a species
#'
#' @description The datapipeline produces many output files. This function
#' creates an standard output file path for those files that are associated with
#' a particular species. There might be instances where we need name that
#'  deviates from the standard. We need to handle these exceptions
#' case by case. Those files that are not associated with a particular species
#' follow different standards.
#' @param prefix A character string with the prefix that will appear at the
#' beginning of the name. This is what distinguishes files within the species
#' directory.
#' @param config A list with pipeline configuration parameters.
#' See \code{\link{configPipeline}}.
#' @param years Character string with years to include in the name.
#' @param sp_code SAFRING reference number of the species we want to analyze.
#' @param ext The extension of the output file. Note that we must add the
#' trailing '.' to the extension.
#'
#' @return A character string with the path to/for a pipeline output file
#' @export
#'
#' @examples
#' \dontrun{
#' config <- configAbu(2017, server = FALSE)
#' sp_code <- 4
#'
#' # Set a file path for a state-space model output
#' setSpOutFilePath("ssm_fit", config, config$years_ch, sp_code, ".rds)
#'
#' # Set a file path for model-ready data
#' setSpOutFilePath("model_data", config, sp_code, ".csv)
#' }
setSpOutFilePath <- function(prefix, config, years, sp_code, ext){
    filename <- paste0(prefix, "_", config$package, "_", years, "_", sp_code, "_", config$region, ext)
    file.path(config$out_dir, sp_code, filename)
}


#' Combine species occupancy diagnostics into a single object
#'
#' @description The datapipeline produces one occupancy diagnostic file for each
#' species and year. This function reads diagnostics files and combines them into
#' a single object
#' @param config A list with pipeline configuration parameters.
#' See \code{\link{configPipeline}}.
#' @param year The year for which diagnostics are required.
#' @param sp_codes SAFRING reference numbers of the species we want diagnostics for.
#'
#' @return A dataframe with diagnostic paramters
#' @export
#'
#' @examples
#' \dontrun{
#' config <- configPipeline(year = 2010,
#'                          dur = 3,
#'                          occ_mod = c("log_dist_coast", "elev", "log_hum.km2", "wetcon",
#'                                      "watrec", "watext", "log_watext", "watext:watrec",
#'                                      "ndvi", "prcp", "tdiff"),
#'                          det_mod = c("(1|obs_id)", "log_hours", "prcp", "tdiff", "cwac"),
#'                          fixed_vars = c("Pentad", "lon", "lat", "watocc_ever", "wetext_2018","wetcon_2018",
#'                                         "dist_coast", "elev"),
#'                          package = "spOccupancy",
#'                          data_dir = "analysis/hpc/imports",
#'                          out_dir = "analysis/hpc/imports",
#'                          server = TRUE)
#' sp_codes <- config$species
#'
#' combineOccuDiags(config, sp_codes, 2008)
#' }
combineOccuDiags <- function(config, sp_codes, year){

    # Create diagnostics object
    diags <- data.frame()

    for(s in seq_along(sp_codes)){
        sp_code <- sp_codes[s]

        # Read in diagnostics
        diagfile <- setSpOutFilePath("occu_diagnostics", config, year, sp_code, ".csv")
        if(file.exists(diagfile)){
            diag <- utils::read.csv(diagfile)
            diags <- dplyr::bind_rows(diags, diag)
        }
    }

    return(diags)
}


#' Combine species abundance diagnostics into a single object
#'
#' @description The data pipeline produces one abundance model diagnostic file for each
#' species and year. This function reads diagnostics files and combines them into
#' a single object
#' @param config A list with pipeline configuration parameters.
#' See \code{\link{configPipeline}}.
#' @param year The year(s) for which diagnostics are required. Years should be formated
#' as the two last digits of the beginning and last years. See
#' @param sp_codes SAFRING reference numbers of the species we want diagnostics for.
#'
#' @return A dataframe with diagnostic paramters
#' @export
#'
#' @examples
#' \dontrun{
#' config <- configPipeline(
#'     year = 2021,
#'     dur = 29,
#'     mod_file = "cwac_ssm_two_season_mean_rev.R",
#'     package = "jagsUI",
#'     data_dir = NULL,
#'     out_dir = NULL,
#'     server = FALSE
#' )
#' sp_codes <- config$species
#'
#' combineAbuDiags(config, sp_codes, "93_21")
#' }
combineAbuDiags <- function(config, sp_codes, year){

    # Create diagnostics object
    diags <- data.frame()

    for(s in seq_along(sp_codes)){
        sp_code <- sp_codes[s]

        # Read in diagnostics
        diagfile <- setSpOutFilePath("abu_diagnostics", config, year, sp_code, ".csv")
        if(file.exists(diagfile)){
            diag <- utils::read.csv(diagfile)
            diags <- dplyr::bind_rows(diags, diag)
        }
    }

    return(diags)
}


#' Add DuToit's Pan data from Doug
#'
#' @description This function is used to attach data from DuToit's Pan that
#' Doug Harebottle provided and that are not on the CWAC database.
#' @param counts A dataframe with CWAC data coming out of \code{\link[CWAC]{getCwacSppCounts}} SAFRING reference number of the species we want to add data to.
#' @param config A list with pipeline configuration parameters.
#' See \code{\link{configPipeline}}.
#'
#' @return A dataframe with DuToit's counts added to `counts`
#' @export
#'
#' @examples
#' \dontrun{
#' config <- configPipeline(
#'     year = 2021,
#'     dur = 29,
#'     mod_file = "cwac_ssm_two_season_mean_rev.R",
#'     package = "jagsUI",
#'     data_dir = NULL,
#'     out_dir = NULL,
#'     server = FALSE
#' )
#'
#' site_code <- 28462448
#'
#' counts <- CWAC::getCwacSiteCounts(site_code)
#'
#' complete_counts <- addDuToitCounts(counts, config)
#'
#'
#' }
addDuToitCounts <- function(counts, config){

    counts <- counts %>%
        dplyr::select(LocationCode, LocationName, Province, Country, Year,
                      Card, StartDate, Season, SppRef, WetIntCode, Species,
                      Common_group, Common_species, Count, CountCondition, X, Y)

    # Add DuToit's Doug's extra data
    dutoit <- utils::read.csv(file.path(config$data_dir, "28462448_data_2022_doug.csv")) %>%
        dplyr::select(LocationCode, LocationName, Province, Country, Year,
                      StartDate, Season, SppRef, WetIntCode, Species,
                      Common_group, Common_species, Count, X, Y)

    # Transfer column types and bind data frames (the below comes from the CWAC package)
    dutoit <- dutoit %>%
        dplyr::mutate(LocationCode = as.character(LocationCode),
                      StartDate = as.Date(StartDate))

    counts <- dplyr::bind_rows(counts, dutoit)

    return(counts)

}
